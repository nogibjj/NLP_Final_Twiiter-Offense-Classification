{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option(\"mode.copy_on_write\", True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/vscode/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/vscode/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/vscode/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Downloading the datasets\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5014</th>\n",
       "      <td>5163</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>@Todd__Kincannon A+ Would expect nothing less ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6503</th>\n",
       "      <td>6686</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>@king__saan I feel like I just got married bru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>1833</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&amp;#8220;@itsDeSha__: I don't take people niggas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12526</th>\n",
       "      <td>12838</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Lmaooo RT @Handsomeesco_55 She a tranny if she...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8036</th>\n",
       "      <td>8261</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bitch I want my number back yo pussy mustard.....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "5014         5163      3            0                   3        0      1   \n",
       "6503         6686      3            0                   3        0      1   \n",
       "1796         1833      6            1                   5        0      1   \n",
       "12526       12838      3            2                   1        0      0   \n",
       "8036         8261      3            0                   3        0      1   \n",
       "\n",
       "                                                   tweet  \n",
       "5014   @Todd__Kincannon A+ Would expect nothing less ...  \n",
       "6503   @king__saan I feel like I just got married bru...  \n",
       "1796   &#8220;@itsDeSha__: I don't take people niggas...  \n",
       "12526  Lmaooo RT @Handsomeesco_55 She a tranny if she...  \n",
       "8036   Bitch I want my number back yo pussy mustard.....  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing the dataset\n",
    "df = pd.read_csv('../../01_Data/01_Raw/raw_tweets.csv')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23763</th>\n",
       "      <td>0</td>\n",
       "      <td>do you think all the rice fags are at McDonald's?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18323</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @_MoonWP_: When dykes hear \"ladies free bef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16370</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @Manstagram_: This bitch went full on retar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9866</th>\n",
       "      <td>1</td>\n",
       "      <td>Hoes will be hoes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12419</th>\n",
       "      <td>1</td>\n",
       "      <td>Like a woman to tell you what she wants you to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class                                              tweet\n",
       "23763      0  do you think all the rice fags are at McDonald's?\n",
       "18323      1  RT @_MoonWP_: When dykes hear \"ladies free bef...\n",
       "16370      1  RT @Manstagram_: This bitch went full on retar...\n",
       "9866       1                                 Hoes will be hoes.\n",
       "12419      1  Like a woman to tell you what she wants you to..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dropping the columns that are not needed\n",
    "df = df[['class', 'tweet']]\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning Process Starts Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create helper colums for cleaning\n",
    "df['clean_tweet'] = df['tweet'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all the text to lower case\n",
    "df['clean_tweet'] = df['clean_tweet'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing URLS\n",
    "def remove_URL(text):\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    return text\n",
    "df['clean_tweet'] = df['clean_tweet'].str.replace(r\"http\\S+\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing mentions\n",
    "def remove_mentions(text):\n",
    "    return re.sub(r'@\\w+', '', text)\n",
    "df['clean_tweet'] = df['clean_tweet'].apply(remove_mentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing hashtags\n",
    "def remove_hashtags(text):\n",
    "    return re.sub(r'#\\w+', '', text)\n",
    "df['clean_tweet'] = df['clean_tweet'].apply(remove_hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing special characters and numbers\n",
    "spl_chrs =  '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "def remove_spl_chrs(text):\n",
    "        text  = \"\".join([_ for _ in text if _ not in spl_chrs])\n",
    "        text = re.sub('[0-9]+', '', text)\n",
    "        return text\n",
    "df['clean_tweet'] = df['clean_tweet'].apply(lambda x: remove_spl_chrs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing stopwords\n",
    "stop = stopwords.words('english')\n",
    "df['clean_tweet'] = df['clean_tweet'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing retweet\n",
    "def remove_rt(text):\n",
    "    return re.sub('^[rt]+', '', text)\n",
    "df['clean_tweet'] = df['clean_tweet'].apply(remove_rt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokenized'] = df[\"clean_tweet\"].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4758</th>\n",
       "      <td>0</td>\n",
       "      <td>@StephyRae7 faggot.</td>\n",
       "      <td>faggot</td>\n",
       "      <td>[faggot]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2655</th>\n",
       "      <td>1</td>\n",
       "      <td>@BosleyXavier I trip on acid not bitches.</td>\n",
       "      <td>ip acid bitches</td>\n",
       "      <td>[ip, acid, bitches]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3648</th>\n",
       "      <td>1</td>\n",
       "      <td>@JerGucci I can trap anywhere I wanna just bec...</td>\n",
       "      <td>ap anywhere wanna aint bitch n rarely solo</td>\n",
       "      <td>[ap, anywhere, wan, na, aint, bitch, n, rarely...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20863</th>\n",
       "      <td>1</td>\n",
       "      <td>Sis said go to sleep I said bitch it's our b d...</td>\n",
       "      <td>sis said go sleep said bitch b day aint sleeping</td>\n",
       "      <td>[sis, said, go, sleep, said, bitch, b, day, ai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>1</td>\n",
       "      <td>\"You can pull more pussy with a dodge and coll...</td>\n",
       "      <td>pull pussy dodge collect panties alright storm...</td>\n",
       "      <td>[pull, pussy, dodge, collect, panties, alright...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class                                              tweet  \\\n",
       "4758       0                                @StephyRae7 faggot.   \n",
       "2655       1          @BosleyXavier I trip on acid not bitches.   \n",
       "3648       1  @JerGucci I can trap anywhere I wanna just bec...   \n",
       "20863      1  Sis said go to sleep I said bitch it's our b d...   \n",
       "607        1  \"You can pull more pussy with a dodge and coll...   \n",
       "\n",
       "                                             clean_tweet  \\\n",
       "4758                                              faggot   \n",
       "2655                                     ip acid bitches   \n",
       "3648          ap anywhere wanna aint bitch n rarely solo   \n",
       "20863   sis said go sleep said bitch b day aint sleeping   \n",
       "607    pull pussy dodge collect panties alright storm...   \n",
       "\n",
       "                                               tokenized  \n",
       "4758                                            [faggot]  \n",
       "2655                                 [ip, acid, bitches]  \n",
       "3648   [ap, anywhere, wan, na, aint, bitch, n, rarely...  \n",
       "20863  [sis, said, go, sleep, said, bitch, b, day, ai...  \n",
       "607    [pull, pussy, dodge, collect, panties, alright...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Stemming and Lematization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming\n",
    "ps = nltk.PorterStemmer()\n",
    "def stemming(text):\n",
    "    text = [ps.stem(word) for word in text]\n",
    "    return text\n",
    "\n",
    "df[\"tokenized\"] = df[\"tokenized\"].apply(lambda x: stemming(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmatization\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "def lemmatizer(text):\n",
    "    text = [wn.lemmatize(word) for word in text]\n",
    "    return text\n",
    "df[\"tokenized\"] = df[\"tokenized\"].apply(lambda x: lemmatizer(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping category 0 from the dataset since it has low values as seen in the EDA\n",
    "df = df[df['class'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Length'] = df['tokenized'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping tweets with 0 length\n",
    "df = df[df['Length'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating simple label for easy identification\n",
    "df['offensive'] = df['class'].apply(lambda x: 'Yes' if x == 1 else 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>Length</th>\n",
       "      <th>offensive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7484</th>\n",
       "      <td>1</td>\n",
       "      <td>Abby doesnt understand how beautiful she is, b...</td>\n",
       "      <td>abby doesnt understand beautiful bitch straigh...</td>\n",
       "      <td>[abbi, doesnt, understand, beauti, bitch, stra...</td>\n",
       "      <td>14</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>2</td>\n",
       "      <td>\"@OSAY_it_aint_so: &amp;#8220;@IgnoreAllLaws: Fost...</td>\n",
       "      <td>fosters home imaginary trash whoa chill show e...</td>\n",
       "      <td>[foster, home, imaginari, trash, whoa, chill, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12841</th>\n",
       "      <td>1</td>\n",
       "      <td>MiMi was so worried bout Stevie J marriage tha...</td>\n",
       "      <td>mimi worried bout stevie j marriage bitch aint...</td>\n",
       "      <td>[mimi, worri, bout, stevi, j, marriag, bitch, ...</td>\n",
       "      <td>15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22960</th>\n",
       "      <td>1</td>\n",
       "      <td>Woke up feeling like a bitch. Gonna stop actin...</td>\n",
       "      <td>woke feeling like bitch gonna stop acting like...</td>\n",
       "      <td>[woke, feel, like, bitch, gon, na, stop, act, ...</td>\n",
       "      <td>15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9385</th>\n",
       "      <td>1</td>\n",
       "      <td>Gave dat bitch da Spirit of the Dragon</td>\n",
       "      <td>gave dat bitch da spirit dragon</td>\n",
       "      <td>[gave, dat, bitch, da, spirit, dragon]</td>\n",
       "      <td>6</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class                                              tweet  \\\n",
       "7484       1  Abby doesnt understand how beautiful she is, b...   \n",
       "205        2  \"@OSAY_it_aint_so: &#8220;@IgnoreAllLaws: Fost...   \n",
       "12841      1  MiMi was so worried bout Stevie J marriage tha...   \n",
       "22960      1  Woke up feeling like a bitch. Gonna stop actin...   \n",
       "9385       1             Gave dat bitch da Spirit of the Dragon   \n",
       "\n",
       "                                             clean_tweet  \\\n",
       "7484   abby doesnt understand beautiful bitch straigh...   \n",
       "205    fosters home imaginary trash whoa chill show e...   \n",
       "12841  mimi worried bout stevie j marriage bitch aint...   \n",
       "22960  woke feeling like bitch gonna stop acting like...   \n",
       "9385                     gave dat bitch da spirit dragon   \n",
       "\n",
       "                                               tokenized  Length offensive  \n",
       "7484   [abbi, doesnt, understand, beauti, bitch, stra...      14       Yes  \n",
       "205    [foster, home, imaginari, trash, whoa, chill, ...       9        No  \n",
       "12841  [mimi, worri, bout, stevi, j, marriag, bitch, ...      15       Yes  \n",
       "22960  [woke, feel, like, bitch, gon, na, stop, act, ...      15       Yes  \n",
       "9385              [gave, dat, bitch, da, spirit, dragon]       6       Yes  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping extra columns\n",
    "df2 = df[['offensive', 'class', 'tokenized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "offensive\n",
       "Yes    19184\n",
       "No      4160\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View Distribution of the classes\n",
    "df2['offensive'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new random sample with 4000 rows from each class\n",
    "df3 = df2.groupby('offensive').apply(lambda x: x.sample(n=4000, random_state=42)).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "offensive\n",
       "No     4000\n",
       "Yes    4000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3['offensive'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offensive</th>\n",
       "      <th>class</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4089</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>[girl, ive, thinkin, way, thinkin, new, way, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>[dont, like, trash, talk, either, way, fair, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>[femal, grand, champion, jess, heard, bird, ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>[oseann, realli, bum, show, woman, note, time,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5800</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>[lmfao, rightrt, knew, sidechick, stop, hate, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     offensive  class                                          tokenized\n",
       "4089       Yes      1  [girl, ive, thinkin, way, thinkin, new, way, b...\n",
       "2479        No      2  [dont, like, trash, talk, either, way, fair, t...\n",
       "1024        No      2  [femal, grand, champion, jess, heard, bird, ou...\n",
       "3260        No      2  [oseann, realli, bum, show, woman, note, time,...\n",
       "5800       Yes      1  [lmfao, rightrt, knew, sidechick, stop, hate, ..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset into train and test sets\n",
    "train, test = train_test_split(df3, test_size=0.20, stratify=df3['offensive'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "offensive\n",
       "Yes    3200\n",
       "No     3200\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['offensive'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "offensive\n",
       "Yes    800\n",
       "No     800\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['offensive'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the datasets\n",
    "train.to_csv('../../01_Data/02_Processed/train.csv', index=False)\n",
    "test.to_csv('../../01_Data/02_Processed/test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configuring Settings\n",
    "pd.set_option(\"mode.copy_on_write\", True)\n",
    "pd.set_option(\"display.max_colwidth\",200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/vscode/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/vscode/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/vscode/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloading the datasets\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21134</th>\n",
       "      <td>21589</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Spring is almost here.. &amp;#171;@Me1st_u_last I realized that my collection of hoes has severely decreased &amp;#128530;&amp;#128530;&amp;#128530;&amp;#128530;&amp;#187;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12346</th>\n",
       "      <td>12658</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Lesson: #NFL is 4 heterosexuals. Wat else do we need besides Michael Sam for us fags to get a clue. Breeders have their thing we have ours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20640</th>\n",
       "      <td>21088</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Scott told me at work today he wants to come over to get me drunk and then seduce my girlfriend...&amp;#128299;&amp;#128298; I'll kill you bitch &amp;#128545;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10843</th>\n",
       "      <td>11124</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>I really want a girl to make me some brownies &amp;#128553;&amp;#128557;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21831</th>\n",
       "      <td>22297</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>These niggas cars be $800 and they have the nerve to put some 2500 rims and some speakers in the bitch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "21134       21589      3            0                   3        0      1   \n",
       "12346       12658      3            0                   2        1      1   \n",
       "20640       21088      3            1                   2        0      1   \n",
       "10843       11124      6            0                   0        6      2   \n",
       "21831       22297      3            0                   3        0      1   \n",
       "\n",
       "                                                                                                                                                     tweet  \n",
       "21134  Spring is almost here.. &#171;@Me1st_u_last I realized that my collection of hoes has severely decreased &#128530;&#128530;&#128530;&#128530;&#187;  \n",
       "12346           Lesson: #NFL is 4 heterosexuals. Wat else do we need besides Michael Sam for us fags to get a clue. Breeders have their thing we have ours  \n",
       "20640   Scott told me at work today he wants to come over to get me drunk and then seduce my girlfriend...&#128299;&#128298; I'll kill you bitch &#128545;  \n",
       "10843                                                                                     I really want a girl to make me some brownies &#128553;&#128557;  \n",
       "21831                                               These niggas cars be $800 and they have the nerve to put some 2500 rims and some speakers in the bitch  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the dataset\n",
    "df = pd.read_csv(\"../../01_Data/01_Raw/raw_tweets.csv\")\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23938</th>\n",
       "      <td>1</td>\n",
       "      <td>holy shit i am just getting dunked on by a cripple this is unreal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6345</th>\n",
       "      <td>1</td>\n",
       "      <td>@karlina_marie your pussy not mine &amp;#128514; do you &amp;#128526;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8949</th>\n",
       "      <td>2</td>\n",
       "      <td>Enjoying My bed. Just perfect For me My Teddy bear and monkey It. #Singlelife #bed #teddybear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22958</th>\n",
       "      <td>1</td>\n",
       "      <td>Woke up cold thenna bitch n stomach on Flat fr &amp;#128514;&amp;#128514;&amp;#128514; http://t.co/71IVR8ISlK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9729</th>\n",
       "      <td>1</td>\n",
       "      <td>He got hoes for sell! Shop with him! #lmfao #TrekGang http://t.co/iuCM6OEVy3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class  \\\n",
       "23938      1   \n",
       "6345       1   \n",
       "8949       2   \n",
       "22958      1   \n",
       "9729       1   \n",
       "\n",
       "                                                                                                   tweet  \n",
       "23938                                  holy shit i am just getting dunked on by a cripple this is unreal  \n",
       "6345                                       @karlina_marie your pussy not mine &#128514; do you &#128526;  \n",
       "8949       Enjoying My bed. Just perfect For me My Teddy bear and monkey It. #Singlelife #bed #teddybear  \n",
       "22958  Woke up cold thenna bitch n stomach on Flat fr &#128514;&#128514;&#128514; http://t.co/71IVR8ISlK  \n",
       "9729                        He got hoes for sell! Shop with him! #lmfao #TrekGang http://t.co/iuCM6OEVy3  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping the columns that are not needed\n",
    "df = df[[\"class\", \"tweet\"]]\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>1</td>\n",
       "      <td>&amp;#8220;@SAVINGNOHOES: When she ask how imma eat her pussy https://t.co/6wVjrC3m1Q&amp;#8221;&amp;#128128;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17285</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SheeeRatchet: When you and your boys discover a hoe&amp;#128514;&amp;#128514;&amp;#128514; https://t.co/QHoHalWQJ2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>1</td>\n",
       "      <td>&amp;#128514;&amp;#128514;&amp;#128514;&amp;#128514; @shoota1017 bitch was mad af https://t.co/9C4i4W7Q7D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10738</th>\n",
       "      <td>1</td>\n",
       "      <td>I love you my nigguh but your a grown ass man https://t.co/utZj6I5Uhj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17117</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @RobIsRandomAF_6: &amp;#128514;&amp;#128514;&amp;#128514;&amp;#128514;&amp;#128514;This bitch came to the club with a broken neck? Bitch you serious? https://t.co/D4bpFhPj6x</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class  \\\n",
       "1504       1   \n",
       "17285      1   \n",
       "992        1   \n",
       "10738      1   \n",
       "17117      1   \n",
       "\n",
       "                                                                                                                                                              tweet  \n",
       "1504                                                              &#8220;@SAVINGNOHOES: When she ask how imma eat her pussy https://t.co/6wVjrC3m1Q&#8221;&#128128;  \n",
       "17285                                                    RT @SheeeRatchet: When you and your boys discover a hoe&#128514;&#128514;&#128514; https://t.co/QHoHalWQJ2  \n",
       "992                                                                       &#128514;&#128514;&#128514;&#128514; @shoota1017 bitch was mad af https://t.co/9C4i4W7Q7D  \n",
       "10738                                                                                         I love you my nigguh but your a grown ass man https://t.co/utZj6I5Uhj  \n",
       "17117  RT @RobIsRandomAF_6: &#128514;&#128514;&#128514;&#128514;&#128514;This bitch came to the club with a broken neck? Bitch you serious? https://t.co/D4bpFhPj6x  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get rows which have https in tweet\n",
    "df.loc[df[\"tweet\"].str.contains(\"https\", na=False)].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class                                                                                                                                             1\n",
       "tweet    My baby Lexy. She is a whole ain't shit bitch in the winter. Sorry ass RWD that's her only flaw. Still love you tho http://t.co/5UGfhrdrxT\n",
       "Name: 12955, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[12955, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning Process Starts Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create helper colums for cleaning\n",
    "df[\"clean_tweet\"] = df[\"tweet\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all the text to lower case\n",
    "df[\"clean_tweet\"] = df[\"clean_tweet\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing URLS\n",
    "def remove_URL(text):\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "df[\"clean_tweet\"] = df[\"clean_tweet\"].apply(remove_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing mentions\n",
    "def remove_mentions(text):\n",
    "    return re.sub(r\"@\\w+\", \"\", text)\n",
    "\n",
    "\n",
    "df[\"clean_tweet\"] = df[\"clean_tweet\"].apply(remove_mentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing hashtags\n",
    "def remove_hashtags(text):\n",
    "    return re.sub(r\"#\\w+\", \"\", text)\n",
    "\n",
    "\n",
    "df[\"clean_tweet\"] = df[\"clean_tweet\"].apply(remove_hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing special characters and numbers\n",
    "spl_chrs = \"!\\\"#$%&'()*+,-./:;<=>?@[\\\\]^_`{|}~\"\n",
    "\n",
    "\n",
    "def remove_spl_chrs(text):\n",
    "    text = \"\".join([_ for _ in text if _ not in spl_chrs])\n",
    "    text = re.sub(\"[0-9]+\", \"\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "df[\"clean_tweet\"] = df[\"clean_tweet\"].apply(lambda x: remove_spl_chrs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing stopwords\n",
    "stop = stopwords.words(\"english\")\n",
    "df[\"clean_tweet\"] = df[\"clean_tweet\"].apply(\n",
    "    lambda x: \" \".join([word for word in x.split() if word not in (stop)])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing retweet\n",
    "def remove_rt(text):\n",
    "    return re.sub(\"^[rt]+\", \"\", text)\n",
    "\n",
    "\n",
    "df[\"clean_tweet\"] = df[\"clean_tweet\"].apply(remove_rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tokenized\"] = df[\"clean_tweet\"].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7661</th>\n",
       "      <td>1</td>\n",
       "      <td>All you ladies pop your pussy like this</td>\n",
       "      <td>ladies pop pussy like</td>\n",
       "      <td>[ladies, pop, pussy, like]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15683</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @Its_KingWalt: Bruh.. Don't do this RT &amp;#8220;@Trent_W93: Females swear their best friend is the baddest bitch in the world!&amp;#8221;</td>\n",
       "      <td>bruh dont rt females swear best friend baddest bitch world</td>\n",
       "      <td>[bruh, dont, rt, females, swear, best, friend, baddest, bitch, world]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19004</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @finlife54: @Vontey_isa_boss &amp;#127797; bitch lol</td>\n",
       "      <td>bitch lol</td>\n",
       "      <td>[bitch, lol]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4800</th>\n",
       "      <td>2</td>\n",
       "      <td>@SugarShai2 youtube bear vs monkey bike race!</td>\n",
       "      <td>youtube bear vs monkey bike race</td>\n",
       "      <td>[youtube, bear, vs, monkey, bike, race]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5610</th>\n",
       "      <td>1</td>\n",
       "      <td>@biggerboat99 please be a little depressed bitch the entire time</td>\n",
       "      <td>please little depressed bitch entire time</td>\n",
       "      <td>[please, little, depressed, bitch, entire, time]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class  \\\n",
       "7661       1   \n",
       "15683      1   \n",
       "19004      1   \n",
       "4800       2   \n",
       "5610       1   \n",
       "\n",
       "                                                                                                                                        tweet  \\\n",
       "7661                                                                                                  All you ladies pop your pussy like this   \n",
       "15683  RT @Its_KingWalt: Bruh.. Don't do this RT &#8220;@Trent_W93: Females swear their best friend is the baddest bitch in the world!&#8221;   \n",
       "19004                                                                                     RT @finlife54: @Vontey_isa_boss &#127797; bitch lol   \n",
       "4800                                                                                            @SugarShai2 youtube bear vs monkey bike race!   \n",
       "5610                                                                         @biggerboat99 please be a little depressed bitch the entire time   \n",
       "\n",
       "                                                       clean_tweet  \\\n",
       "7661                                         ladies pop pussy like   \n",
       "15683   bruh dont rt females swear best friend baddest bitch world   \n",
       "19004                                                    bitch lol   \n",
       "4800                              youtube bear vs monkey bike race   \n",
       "5610                     please little depressed bitch entire time   \n",
       "\n",
       "                                                                   tokenized  \n",
       "7661                                              [ladies, pop, pussy, like]  \n",
       "15683  [bruh, dont, rt, females, swear, best, friend, baddest, bitch, world]  \n",
       "19004                                                           [bitch, lol]  \n",
       "4800                                 [youtube, bear, vs, monkey, bike, race]  \n",
       "5610                        [please, little, depressed, bitch, entire, time]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class                                                                                                                                                   1\n",
       "tweet          My baby Lexy. She is a whole ain't shit bitch in the winter. Sorry ass RWD that's her only flaw. Still love you tho http://t.co/5UGfhrdrxT\n",
       "clean_tweet                                                                baby lexy whole aint shit bitch winter sorry ass rwd thats flaw still love tho\n",
       "tokenized                                                  [baby, lexy, whole, aint, shit, bitch, winter, sorry, ass, rwd, thats, flaw, still, love, tho]\n",
       "Name: 12955, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confirm if HTTPs are removed\n",
    "df.iloc[12955,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Stemming and Lematization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "\n",
    "def stemming(text):\n",
    "    text = [ps.stem(word) for word in text]\n",
    "    return text\n",
    "\n",
    "\n",
    "df[\"tokenized\"] = df[\"tokenized\"].apply(lambda x: stemming(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def lemmatizer(text):\n",
    "    text = [wn.lemmatize(word) for word in text]\n",
    "    return text\n",
    "\n",
    "\n",
    "df[\"tokenized\"] = df[\"tokenized\"].apply(lambda x: lemmatizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regenrate the clean tweet\n",
    "def regen_tweet(text):\n",
    "    return \" \".join(text)\n",
    "df[\"clean_tweet\"] = df[\"tokenized\"].apply(lambda x: regen_tweet(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11362</th>\n",
       "      <td>1</td>\n",
       "      <td>I'm pretty sure the dmv won't let me take a new pic, but a bitch might accidentally lose my license again where they have to take a new pic</td>\n",
       "      <td>im pretti sure dmv wont let take new pic bitch might accident lose licens take new pic</td>\n",
       "      <td>[im, pretti, sure, dmv, wont, let, take, new, pic, bitch, might, accident, lose, licens, take, new, pic]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20570</th>\n",
       "      <td>1</td>\n",
       "      <td>Rusty hoe to bumpin 2 me #NeedDaName http://t.co/DwAEjyUbQr</td>\n",
       "      <td>usti hoe bumpin</td>\n",
       "      <td>[usti, hoe, bumpin]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11331</th>\n",
       "      <td>2</td>\n",
       "      <td>I'm not big on the \"Uncle Tom\" slur anyway, but can we at least reserve it for those who earn it, not just those who dare to not vote Dem?</td>\n",
       "      <td>im big uncl tom slur anyway least reserv earn dare vote dem</td>\n",
       "      <td>[im, big, uncl, tom, slur, anyway, least, reserv, earn, dare, vote, dem]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20421</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @yungkatana: free wop</td>\n",
       "      <td>free wop</td>\n",
       "      <td>[free, wop]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15305</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @GLODEH: Her shitty booty ass talm about its a prep rally. How bitch how? What y'all preparing for? &amp;#128514;&amp;#128514;&amp;#128514;</td>\n",
       "      <td>shitti booti as talm prep ralli bitch yall prepar</td>\n",
       "      <td>[shitti, booti, as, talm, prep, ralli, bitch, yall, prepar]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class  \\\n",
       "11362      1   \n",
       "20570      1   \n",
       "11331      2   \n",
       "20421      1   \n",
       "15305      1   \n",
       "\n",
       "                                                                                                                                             tweet  \\\n",
       "11362  I'm pretty sure the dmv won't let me take a new pic, but a bitch might accidentally lose my license again where they have to take a new pic   \n",
       "20570                                                                                  Rusty hoe to bumpin 2 me #NeedDaName http://t.co/DwAEjyUbQr   \n",
       "11331   I'm not big on the \"Uncle Tom\" slur anyway, but can we at least reserve it for those who earn it, not just those who dare to not vote Dem?   \n",
       "20421                                                                                                                     RT @yungkatana: free wop   \n",
       "15305           RT @GLODEH: Her shitty booty ass talm about its a prep rally. How bitch how? What y'all preparing for? &#128514;&#128514;&#128514;   \n",
       "\n",
       "                                                                                  clean_tweet  \\\n",
       "11362  im pretti sure dmv wont let take new pic bitch might accident lose licens take new pic   \n",
       "20570                                                                         usti hoe bumpin   \n",
       "11331                             im big uncl tom slur anyway least reserv earn dare vote dem   \n",
       "20421                                                                                free wop   \n",
       "15305                                       shitti booti as talm prep ralli bitch yall prepar   \n",
       "\n",
       "                                                                                                      tokenized  \n",
       "11362  [im, pretti, sure, dmv, wont, let, take, new, pic, bitch, might, accident, lose, licens, take, new, pic]  \n",
       "20570                                                                                       [usti, hoe, bumpin]  \n",
       "11331                                  [im, big, uncl, tom, slur, anyway, least, reserv, earn, dare, vote, dem]  \n",
       "20421                                                                                               [free, wop]  \n",
       "15305                                               [shitti, booti, as, talm, prep, ralli, bitch, yall, prepar]  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping category 0 from the dataset since it has low values as seen in the EDA\n",
    "df = df[df[\"class\"] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Length\"] = df[\"tokenized\"].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping tweets with 0 length\n",
    "df = df[df[\"Length\"] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating simple label for easy identification\n",
    "df[\"offensive\"] = df[\"class\"].apply(lambda x: \"Yes\" if x == 1 else \"No\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>Length</th>\n",
       "      <th>offensive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2354</th>\n",
       "      <td>1</td>\n",
       "      <td>@ASAP_RocKI_ @HuhWhatsACondom *sighs* 1. Not a bitch. I'm a woman. LEARN THE DIFFERENCE. 2. I KNOW I'm fat. 3. It's called a scarf, dumbass.</td>\n",
       "      <td>sigh bitch im woman learn differ know im fat call scarf dumbass</td>\n",
       "      <td>[sigh, bitch, im, woman, learn, differ, know, im, fat, call, scarf, dumbass]</td>\n",
       "      <td>12</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2379</th>\n",
       "      <td>1</td>\n",
       "      <td>@Adolfhibsta I've seen a number of bitches on here say there's no such thing as loose pussy lol. Ok</td>\n",
       "      <td>ive seen number bitch say there thing loo pussi lol ok</td>\n",
       "      <td>[ive, seen, number, bitch, say, there, thing, loo, pussi, lol, ok]</td>\n",
       "      <td>11</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23290</th>\n",
       "      <td>1</td>\n",
       "      <td>You da bess, you deserve a crown bitch!</td>\n",
       "      <td>da be deserv crown bitch</td>\n",
       "      <td>[da, be, deserv, crown, bitch]</td>\n",
       "      <td>5</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8631</th>\n",
       "      <td>1</td>\n",
       "      <td>Damn some Oreos would be so fucking clutch right now!!!</td>\n",
       "      <td>damn oreo would fuck clutch right</td>\n",
       "      <td>[damn, oreo, would, fuck, clutch, right]</td>\n",
       "      <td>6</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2552</th>\n",
       "      <td>1</td>\n",
       "      <td>@BarackObama make weed legal you pussy you know you smoke that shit</td>\n",
       "      <td>make weed legal pussi know smoke shit</td>\n",
       "      <td>[make, weed, legal, pussi, know, smoke, shit]</td>\n",
       "      <td>7</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class  \\\n",
       "2354       1   \n",
       "2379       1   \n",
       "23290      1   \n",
       "8631       1   \n",
       "2552       1   \n",
       "\n",
       "                                                                                                                                              tweet  \\\n",
       "2354   @ASAP_RocKI_ @HuhWhatsACondom *sighs* 1. Not a bitch. I'm a woman. LEARN THE DIFFERENCE. 2. I KNOW I'm fat. 3. It's called a scarf, dumbass.   \n",
       "2379                                            @Adolfhibsta I've seen a number of bitches on here say there's no such thing as loose pussy lol. Ok   \n",
       "23290                                                                                                       You da bess, you deserve a crown bitch!   \n",
       "8631                                                                                        Damn some Oreos would be so fucking clutch right now!!!   \n",
       "2552                                                                            @BarackObama make weed legal you pussy you know you smoke that shit   \n",
       "\n",
       "                                                           clean_tweet  \\\n",
       "2354   sigh bitch im woman learn differ know im fat call scarf dumbass   \n",
       "2379            ive seen number bitch say there thing loo pussi lol ok   \n",
       "23290                                         da be deserv crown bitch   \n",
       "8631                                 damn oreo would fuck clutch right   \n",
       "2552                             make weed legal pussi know smoke shit   \n",
       "\n",
       "                                                                          tokenized  \\\n",
       "2354   [sigh, bitch, im, woman, learn, differ, know, im, fat, call, scarf, dumbass]   \n",
       "2379             [ive, seen, number, bitch, say, there, thing, loo, pussi, lol, ok]   \n",
       "23290                                                [da, be, deserv, crown, bitch]   \n",
       "8631                                       [damn, oreo, would, fuck, clutch, right]   \n",
       "2552                                  [make, weed, legal, pussi, know, smoke, shit]   \n",
       "\n",
       "       Length offensive  \n",
       "2354       12       Yes  \n",
       "2379       11       Yes  \n",
       "23290       5       Yes  \n",
       "8631        6       Yes  \n",
       "2552        7       Yes  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping extra columns\n",
    "df2 = df[[\"offensive\", \"class\", \"tokenized\", \"clean_tweet\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "offensive\n",
       "Yes    19181\n",
       "No      4156\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View Distribution of the classes\n",
    "df2[\"offensive\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new random sample with 4000 rows from each class\n",
    "df3 = (\n",
    "    df2.groupby(\"offensive\")\n",
    "    .apply(lambda x: x.sample(n=4000, random_state=42))\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "offensive\n",
       "No     4000\n",
       "Yes    4000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3[\"offensive\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offensive</th>\n",
       "      <th>class</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3582</th>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>[happi, birthday, pop, old, negro, spiritu, today, lol]</td>\n",
       "      <td>happi birthday pop old negro spiritu today lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830</th>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>[last, thought, bed, mock, elect, rd, grade, vote, perot, mayb, relat, realli, big, ear, idk]</td>\n",
       "      <td>last thought bed mock elect rd grade vote perot mayb relat realli big ear idk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3039</th>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>[hillari, dodo, bird, candid, via]</td>\n",
       "      <td>hillari dodo bird candid via</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5684</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>[never, follow, bitch, who, bio, look, like]</td>\n",
       "      <td>never follow bitch who bio look like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3730</th>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>[whoever, mock, poor, insult, maker, glad, calam, go, unpunish]</td>\n",
       "      <td>whoever mock poor insult maker glad calam go unpunish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     offensive  class  \\\n",
       "3582        No      2   \n",
       "2830        No      2   \n",
       "3039        No      2   \n",
       "5684       Yes      1   \n",
       "3730        No      2   \n",
       "\n",
       "                                                                                          tokenized  \\\n",
       "3582                                        [happi, birthday, pop, old, negro, spiritu, today, lol]   \n",
       "2830  [last, thought, bed, mock, elect, rd, grade, vote, perot, mayb, relat, realli, big, ear, idk]   \n",
       "3039                                                             [hillari, dodo, bird, candid, via]   \n",
       "5684                                                   [never, follow, bitch, who, bio, look, like]   \n",
       "3730                                [whoever, mock, poor, insult, maker, glad, calam, go, unpunish]   \n",
       "\n",
       "                                                                        clean_tweet  \n",
       "3582                                 happi birthday pop old negro spiritu today lol  \n",
       "2830  last thought bed mock elect rd grade vote perot mayb relat realli big ear idk  \n",
       "3039                                                   hillari dodo bird candid via  \n",
       "5684                                           never follow bitch who bio look like  \n",
       "3730                          whoever mock poor insult maker glad calam go unpunish  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing the class labels 2 with 0 for easy use in models\n",
    "df3[\"class\"] = df3[\"class\"].replace(2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>offensive</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class offensive  count\n",
       "0      0        No   4000\n",
       "1      1       Yes   4000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confirm the mapping\n",
    "df3[['class','offensive']].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test sets at 80:20 ratio\n",
    "train, test = train_test_split(\n",
    "    df3, test_size=0.20, stratify=df3[\"offensive\"], random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "offensive\n",
       "Yes    3200\n",
       "No     3200\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"offensive\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "offensive\n",
       "Yes    800\n",
       "No     800\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"offensive\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the datasets\n",
    "train.to_csv(\"../../01_Data/02_Processed/train.csv\", index=False)\n",
    "test.to_csv(\"../../01_Data/02_Processed/test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

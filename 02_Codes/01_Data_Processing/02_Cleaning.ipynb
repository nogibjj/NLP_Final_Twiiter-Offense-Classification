{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option(\"mode.copy_on_write\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/vscode/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /home/vscode/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to /home/vscode/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloading the datasets\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>169</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>\"@LODYCASH: dry pussy bitches always blame it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>1161</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&amp;#8220;@Benkasso: I'll beat the pussy up, that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9929</th>\n",
       "      <td>10201</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>How my bestf gon call me \" People \" like ima r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22647</th>\n",
       "      <td>23125</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>What's up with all these bitches in bed clothe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14372</th>\n",
       "      <td>14715</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @BigDaddyTise: &amp;#8220;@Mr_popular: Bald hea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "167           169      3            0                   3        0      1   \n",
       "1136         1161      9            1                   8        0      1   \n",
       "9929        10201      3            1                   2        0      1   \n",
       "22647       23125      3            0                   3        0      1   \n",
       "14372       14715      3            0                   2        1      1   \n",
       "\n",
       "                                                   tweet  \n",
       "167    \"@LODYCASH: dry pussy bitches always blame it ...  \n",
       "1136   &#8220;@Benkasso: I'll beat the pussy up, that...  \n",
       "9929   How my bestf gon call me \" People \" like ima r...  \n",
       "22647  What's up with all these bitches in bed clothe...  \n",
       "14372  RT @BigDaddyTise: &#8220;@Mr_popular: Bald hea...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the dataset\n",
    "df = pd.read_csv(\"../../01_Data/01_Raw/raw_tweets.csv\")\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12455</th>\n",
       "      <td>1</td>\n",
       "      <td>Lil cuz need to help a bitch out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3160</th>\n",
       "      <td>1</td>\n",
       "      <td>@Fapplebee dude tell me why that's so true my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20187</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @tic14tac: Guys be like \"Man, fuck that bit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22532</th>\n",
       "      <td>1</td>\n",
       "      <td>We need to start having a fantasy team of UT h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21276</th>\n",
       "      <td>2</td>\n",
       "      <td>Taking out a second mortgage and betting it al...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class                                              tweet\n",
       "12455      1                   Lil cuz need to help a bitch out\n",
       "3160       1  @Fapplebee dude tell me why that's so true my ...\n",
       "20187      1  RT @tic14tac: Guys be like \"Man, fuck that bit...\n",
       "22532      1  We need to start having a fantasy team of UT h...\n",
       "21276      2  Taking out a second mortgage and betting it al..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping the columns that are not needed\n",
    "df = df[[\"class\", \"tweet\"]]\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning Process Starts Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create helper colums for cleaning\n",
    "df[\"clean_tweet\"] = df[\"tweet\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all the text to lower case\n",
    "df[\"clean_tweet\"] = df[\"clean_tweet\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing URLS\n",
    "def remove_URL(text):\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "df[\"clean_tweet\"] = df[\"clean_tweet\"].str.replace(r\"http\\S+\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing mentions\n",
    "def remove_mentions(text):\n",
    "    return re.sub(r\"@\\w+\", \"\", text)\n",
    "\n",
    "\n",
    "df[\"clean_tweet\"] = df[\"clean_tweet\"].apply(remove_mentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing hashtags\n",
    "def remove_hashtags(text):\n",
    "    return re.sub(r\"#\\w+\", \"\", text)\n",
    "\n",
    "\n",
    "df[\"clean_tweet\"] = df[\"clean_tweet\"].apply(remove_hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing special characters and numbers\n",
    "spl_chrs = \"!\\\"#$%&'()*+,-./:;<=>?@[\\\\]^_`{|}~\"\n",
    "\n",
    "\n",
    "def remove_spl_chrs(text):\n",
    "    text = \"\".join([_ for _ in text if _ not in spl_chrs])\n",
    "    text = re.sub(\"[0-9]+\", \"\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "df[\"clean_tweet\"] = df[\"clean_tweet\"].apply(lambda x: remove_spl_chrs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing stopwords\n",
    "stop = stopwords.words(\"english\")\n",
    "df[\"clean_tweet\"] = df[\"clean_tweet\"].apply(\n",
    "    lambda x: \" \".join([word for word in x.split() if word not in (stop)])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing retweet\n",
    "def remove_rt(text):\n",
    "    return re.sub(\"^[rt]+\", \"\", text)\n",
    "\n",
    "\n",
    "df[\"clean_tweet\"] = df[\"clean_tweet\"].apply(remove_rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tokenized\"] = df[\"clean_tweet\"].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>1</td>\n",
       "      <td>@FreddieGibbs Lol, always with the complaining...</td>\n",
       "      <td>lol always complaining crying like jeezy broke...</td>\n",
       "      <td>[lol, always, complaining, crying, like, jeezy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8925</th>\n",
       "      <td>1</td>\n",
       "      <td>Eat her pussy when she mad\\nEat her pussy when...</td>\n",
       "      <td>eat pussy mad eat pussy sad eat pussy sleep ea...</td>\n",
       "      <td>[eat, pussy, mad, eat, pussy, sad, eat, pussy,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>0</td>\n",
       "      <td>&amp;#8220;@TP_Three: @WestSideFlee @KekePalmer da...</td>\n",
       "      <td>damn got wifey fall back nigga dont share hoes</td>\n",
       "      <td>[damn, got, wifey, fall, back, nigga, dont, sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3231</th>\n",
       "      <td>2</td>\n",
       "      <td>@GWDrums @samzbikowski Oh, wait! *\"can I get t...</td>\n",
       "      <td>oh wait get photo playin creeds side project b...</td>\n",
       "      <td>[oh, wait, get, photo, playin, creeds, side, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13162</th>\n",
       "      <td>1</td>\n",
       "      <td>My worse bitch looks better than your main bit...</td>\n",
       "      <td>worse bitch looks better main bitch thats bad ...</td>\n",
       "      <td>[worse, bitch, looks, better, main, bitch, tha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class                                              tweet  \\\n",
       "3197       1  @FreddieGibbs Lol, always with the complaining...   \n",
       "8925       1  Eat her pussy when she mad\\nEat her pussy when...   \n",
       "1542       0  &#8220;@TP_Three: @WestSideFlee @KekePalmer da...   \n",
       "3231       2  @GWDrums @samzbikowski Oh, wait! *\"can I get t...   \n",
       "13162      1  My worse bitch looks better than your main bit...   \n",
       "\n",
       "                                             clean_tweet  \\\n",
       "3197   lol always complaining crying like jeezy broke...   \n",
       "8925   eat pussy mad eat pussy sad eat pussy sleep ea...   \n",
       "1542      damn got wifey fall back nigga dont share hoes   \n",
       "3231   oh wait get photo playin creeds side project b...   \n",
       "13162  worse bitch looks better main bitch thats bad ...   \n",
       "\n",
       "                                               tokenized  \n",
       "3197   [lol, always, complaining, crying, like, jeezy...  \n",
       "8925   [eat, pussy, mad, eat, pussy, sad, eat, pussy,...  \n",
       "1542   [damn, got, wifey, fall, back, nigga, dont, sh...  \n",
       "3231   [oh, wait, get, photo, playin, creeds, side, p...  \n",
       "13162  [worse, bitch, looks, better, main, bitch, tha...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Stemming and Lematization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "\n",
    "def stemming(text):\n",
    "    text = [ps.stem(word) for word in text]\n",
    "    return text\n",
    "\n",
    "\n",
    "df[\"tokenized\"] = df[\"tokenized\"].apply(lambda x: stemming(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def lemmatizer(text):\n",
    "    text = [wn.lemmatize(word) for word in text]\n",
    "    return text\n",
    "\n",
    "\n",
    "df[\"tokenized\"] = df[\"tokenized\"].apply(lambda x: lemmatizer(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping category 0 from the dataset since it has low values as seen in the EDA\n",
    "df = df[df[\"class\"] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Length\"] = df[\"tokenized\"].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping tweets with 0 length\n",
    "df = df[df[\"Length\"] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating simple label for easy identification\n",
    "df[\"offensive\"] = df[\"class\"].apply(lambda x: \"Yes\" if x == 1 else \"No\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>Length</th>\n",
       "      <th>offensive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19812</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @oweeSheREDD: you tell ya business to ah bi...</td>\n",
       "      <td>tell ya business ah bitch cant trust ya</td>\n",
       "      <td>[tell, ya, busi, ah, bitch, cant, trust, ya]</td>\n",
       "      <td>8</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19483</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @kylegotjokes: Me when your bitch favorites...</td>\n",
       "      <td>bitch favorites tweets httptcomaokzqlaos</td>\n",
       "      <td>[bitch, favorit, tweet, httptcomaokzqlao]</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7784</th>\n",
       "      <td>1</td>\n",
       "      <td>Any nicca gettin it n da ass is a fag! &amp;#8220;...</td>\n",
       "      <td>nicca gettin n da ass fag howw please explain ...</td>\n",
       "      <td>[nicca, gettin, n, da, as, fag, howw, plea, ex...</td>\n",
       "      <td>13</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6822</th>\n",
       "      <td>1</td>\n",
       "      <td>@peighxo @baestation bitch got arms like piccolo</td>\n",
       "      <td>bitch got arms like piccolo</td>\n",
       "      <td>[bitch, got, arm, like, piccolo]</td>\n",
       "      <td>5</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10089</th>\n",
       "      <td>1</td>\n",
       "      <td>I broke baby outta his thug stage n turned him...</td>\n",
       "      <td>broke baby outta thug stage n turned pussy har...</td>\n",
       "      <td>[broke, babi, outta, thug, stage, n, turn, pus...</td>\n",
       "      <td>13</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class                                              tweet  \\\n",
       "19812      1  RT @oweeSheREDD: you tell ya business to ah bi...   \n",
       "19483      1  RT @kylegotjokes: Me when your bitch favorites...   \n",
       "7784       1  Any nicca gettin it n da ass is a fag! &#8220;...   \n",
       "6822       1   @peighxo @baestation bitch got arms like piccolo   \n",
       "10089      1  I broke baby outta his thug stage n turned him...   \n",
       "\n",
       "                                             clean_tweet  \\\n",
       "19812            tell ya business ah bitch cant trust ya   \n",
       "19483           bitch favorites tweets httptcomaokzqlaos   \n",
       "7784   nicca gettin n da ass fag howw please explain ...   \n",
       "6822                         bitch got arms like piccolo   \n",
       "10089  broke baby outta thug stage n turned pussy har...   \n",
       "\n",
       "                                               tokenized  Length offensive  \n",
       "19812       [tell, ya, busi, ah, bitch, cant, trust, ya]       8       Yes  \n",
       "19483          [bitch, favorit, tweet, httptcomaokzqlao]       4       Yes  \n",
       "7784   [nicca, gettin, n, da, as, fag, howw, plea, ex...      13       Yes  \n",
       "6822                    [bitch, got, arm, like, piccolo]       5       Yes  \n",
       "10089  [broke, babi, outta, thug, stage, n, turn, pus...      13       Yes  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping extra columns\n",
    "df2 = df[[\"offensive\", \"class\", \"tokenized\", \"clean_tweet\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "offensive\n",
       "Yes    19184\n",
       "No      4160\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View Distribution of the classes\n",
    "df2[\"offensive\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new random sample with 4000 rows from each class\n",
    "df3 = (\n",
    "    df2.groupby(\"offensive\")\n",
    "    .apply(lambda x: x.sample(n=4000, random_state=42))\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "offensive\n",
       "No     4000\n",
       "Yes    4000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3[\"offensive\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offensive</th>\n",
       "      <th>class</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1729</th>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>[run, differentialsmet, yanke]</td>\n",
       "      <td>run differentialsmets yankees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3427</th>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>[would, spend, money, trash, like]</td>\n",
       "      <td>would spend money trash like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>[leav, whine, infrastructur, r, one, wont, pay...</td>\n",
       "      <td>leave whine infrastructure r ones wont pay wai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6787</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>[witter, say, ridin, niggah, that, realli, fuc...</td>\n",
       "      <td>witter say ridin niggah thats really fuck pull...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7145</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>[lil, bitch, bu, stop, adida, flipflop, amp, s...</td>\n",
       "      <td>lil bitch bus stop adidas flipflops amp socks ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     offensive  class                                          tokenized  \\\n",
       "1729        No      2                     [run, differentialsmet, yanke]   \n",
       "3427        No      2                 [would, spend, money, trash, like]   \n",
       "1616        No      2  [leav, whine, infrastructur, r, one, wont, pay...   \n",
       "6787       Yes      1  [witter, say, ridin, niggah, that, realli, fuc...   \n",
       "7145       Yes      1  [lil, bitch, bu, stop, adida, flipflop, amp, s...   \n",
       "\n",
       "                                            clean_tweet  \n",
       "1729                      run differentialsmets yankees  \n",
       "3427                       would spend money trash like  \n",
       "1616  leave whine infrastructure r ones wont pay wai...  \n",
       "6787  witter say ridin niggah thats really fuck pull...  \n",
       "7145  lil bitch bus stop adidas flipflops amp socks ...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test sets\n",
    "train, test = train_test_split(\n",
    "    df3, test_size=0.20, stratify=df3[\"offensive\"], random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "offensive\n",
       "Yes    3200\n",
       "No     3200\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"offensive\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "offensive\n",
       "Yes    800\n",
       "No     800\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"offensive\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the datasets\n",
    "train.to_csv(\"../../01_Data/02_Processed/train.csv\", index=False)\n",
    "test.to_csv(\"../../01_Data/02_Processed/test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
